<!doctype html>
<head>
  <script type="text/javascript" src="../src/lokijs.js"></script>
</head>
<h2>Hi!</h2>

<script>
  var db



  function IncremenentalAdapter() {
    this.mode = 'reference'
    this.chunkSize = 100
    // this.chunkSize = 5
    this.idb = null // will be lazily loaded on first operation that needs it
  }

  // chunkId - index of the data chunk - e.g. chunk 0 will be lokiIds 0-99
  IncremenentalAdapter.prototype._getChunk = function(collection, chunkId) {
    // 0-99, 100-199, etc.
    // (loki starts $loki ids with 1, but that could change so just to be safe…)
    const minId = chunkId * this.chunkSize
    const maxId = minId + this.chunkSize - 1

    // use idIndex to find first collection.data position within the $loki range
    const idIndex = collection.idIndex

    // TODO: Proper binary search would be MUCH faster - this fast path works
    // only if minId exists
    let firstDataPosition = null

    let getId = collection.get(minId, true)
    if (getId) {
      firstDataPosition = getId[1]
    } else {
      for (let i = 0, length = idIndex.length; i < length; i++) {
        if (idIndex[i] >= minId && idIndex[i] <= maxId) {
          firstDataPosition = i
          break
        }
      }
    }

    if (firstDataPosition === null) {
      // no elements in this chunk
      return []
    }

    // find last position
    // if loki IDs are contiguous (no removed elements)
    // last position will be first + chunk - 1
    // (and we look back in case there are missing pieces)
    // TODO: Binary search
    let lastDataPosition = null
    for (let i = firstDataPosition + this.chunkSize - 1; i >= firstDataPosition; i--) {
      if (idIndex[i] <= maxId) {
        lastDataPosition = i
        break
      }
    }

    // sanity check
    // TODO: remove me
    const firstElement = collection.data[firstDataPosition]
    if (!(firstElement && firstElement.$loki >= minId && firstElement.$loki <= maxId)) {
      throw new Error('broken invariant firstelement')
    }

    const lastElement = collection.data[lastDataPosition]
    if (!(lastElement && lastElement.$loki >= minId && lastElement.$loki <= maxId)) {
      throw new Error('broken invariant lastElement')
    }

    // this will have *up to* `this.chunkSize` elements (might have less, because $loki ids
    // will have holes when data is deleted)
    const chunkData = collection.data.slice(firstDataPosition, lastDataPosition + 1)
    // const chunkData = []
    // for (let i = firstDataPosition; true; i++) {
    //   const element = collection.data[i]
    //   // TODO: Remove sanity check
    //   if (element && element.$loki < minId) {
    //     throw new Error('broken invariant minid')
    //   }
    //   if (element && element.$loki <= maxId) {
    //     chunkData.push(element)
    //   } else {
    //     break
    //   }
    // }

    // TODO: Remove sanity check
    if (chunkData.length > this.chunkSize) {
      throw new Error('broken invariant - chunk size')
    }

    return chunkData
  }

  IncremenentalAdapter.prototype.exportDatabase = function(dbname, loki, callback) {
    console.warn(`-- exportDatabase - begin`)
    console.time('exportDatabase')
    console.log(loki.collections[0].lokiIdChanges)

    let chunksToSave = []

    console.time('makeChunks')
    loki.collections.forEach(collection => {
      // TODO: do we need to separate inserted and updated?
      // get deduplicated ids
      // const idsToSave = new Set(changes.inserted.concat(changes.updated))
      // const idsToRemove = new Set(changes.removed)
      // idsToRemove.forEach(id => {
        //   idsToSave.delete(id)
        // })
      // const changes = collection.lokiIdChanges
      // const dirtyLokiIds = new Set(changes.inserted.concat(changes.updated).concat(changes.removed))
      // collection.lokiIdChanges = null

      // // prepare chunks to save and remove
      // idsToSave.forEach(id => {
      //   // TODO: error handling on get
      //   chunksToSave.push([collection.name + '.' + id, collection.get(id)])
      // })
      // idsToRemove.forEach(id => {
      //   chunkIdsToRemove.push(collection.name + '.' + id)
      // })

      console.time('get dirty chunk ids')
      const dirtyChunks = new Set()
      collection.dirtyIds.forEach(lokiId => {
        const chunkId = lokiId / this.chunkSize | 0
        dirtyChunks.add(chunkId)
      })
      collection.dirtyIds = null
      console.timeEnd('get dirty chunk ids')

      console.time('get chunks&serialize')
      dirtyChunks.forEach(chunkId => {
        // console.time('get chunk')
        const chunkData = this._getChunk(collection, chunkId)
        // console.timeEnd('get chunk')
        // we must stringify, because IDB is asynchronous, and underlying objects are mutable
        // console.time('stringify chunk')
        const chunkJSON = JSON.stringify(chunkData)
        chunksToSave.push({ key: collection.name + '.chunk.' + chunkId, value: chunkJSON})
        // console.timeEnd('stringify chunk')
      })
      console.timeEnd('get chunks&serialize')

      // clear out data as we won't be saving it
      collection.data = []
    })
    console.timeEnd('makeChunks')

    console.time('loki-serialized')
    const serializedMetadata = JSON.stringify(loki)
    loki = null // allow GC of the DB copy

    console.log(chunksToSave)
    // console.log(chunkIdsToRemove)
    console.log(JSON.parse(serializedMetadata))

    chunksToSave.push({ key: 'loki', value: serializedMetadata })
    console.timeEnd('loki-serialized')

    // TODO: Clear out lokiChangedIds flags on original database

    this._saveChunks(chunksToSave, callback)




    // if (success) {
    //   callback(null);
    // }
    // else {
    //   callback(new Error("some error occurred."));
    // }
  }



  IncremenentalAdapter.prototype.loadDatabase = function(dbname, callback) {
    console.warn(`-- loadDatabase - begin`)
    console.time('loadDatabase')
    this._getAllChunks(chunks => {

      if (!chunks.length) {
        console.log(`No chunks`)
        callback(null)
        return
      }

      console.log(`Found chunks:`, chunks)

      // sort chunks in place to load data in the right order (ascending loki ids)
      // at least on Safari, we'll get chunks in order like this: 0, 1, 10, 100...
      console.time('sort')
      const getSortKey = function({ key }) {
        if (key.includes('.')) {
          const segments = key.split('.')
          if (segments.length === 3) {
            return parseInt(segments[2], 10)
          }
        }

        return key
      }
      chunks.sort(function(a, b) {
        const aKey = getSortKey(a), bKey =getSortKey(b);
        if(aKey < bKey) return -1;
        if(aKey > bKey) return 1;
        return 0;
      });
      console.timeEnd('sort')
      console.log(`Sorted chunks`, chunks)

      // repack chunks into a map
      let loki
      let collections = {}

      console.time('repack')
      chunks.forEach(({ key, value }) => {
        if (key === 'loki') {
          loki = value
        } else if (key.includes('.')) {
          const keySegments = key.split('.')
          if (keySegments.length === 3 && keySegments[1] === 'chunk') {
            const colName = keySegments[0]
            if (collections[colName]) {
              collections[colName].push(value)
            } else {
              collections[colName] = [value]
            }
          } else {
            throw new Error('unknown chunk')
          }
        } else {
          throw new Error('unknown chunk')
        }
      })
      chunks = null
      console.timeEnd('repack')
      console.log(`Collections`, collections)

      // TODO: Validate collection chunks?
      if (!loki) {
        throw new Error('missing loki…')
      }

      // parse Loki object
      console.time('parse')
      loki = JSON.parse(loki)
      console.timeEnd('parse')
      console.log(`Parsed loki object`, loki)

      // populate collections with data
      console.time('populate')
      this._populate(loki, collections)
      collections = null
      console.timeEnd('populate')

      // instantiate actual Loki object
      console.timeEnd('loadDatabase')
      console.log(`Loaded Loki database!`, loki)
      callback(loki)
    })


    // if (success) {
    //   callback(newSerialized);
    // }
    // else {
    //   callback(new Error("some error"));
    // }
  }

  IncremenentalAdapter.prototype._populate = function(loki, collections) {
    loki.collections.forEach(collection => {
    // for(let k = 0, kLen = loki.collections.length; k < kLen; k++) {
    //   const collection = loki.collections[k]
      const dataChunks = collections[collection.name]

      if (dataChunks) {
        // console.log(`Importing ${dataChunks.length} chunks into ${collection.name}`)

        dataChunks.forEach((chunkObj, i) => {
        // for (let j = 0, jLen = dataChunks.length; j < jLen; j++) {
          const chunk = JSON.parse(chunkObj)
          // const chunk = []
          chunkObj = null
          dataChunks[i] = null

          // for (let i = 0, len = chunk.length; i < len; i++) {
            // collection.data.push(chunk[i])
          // }
          chunk.forEach(doc => {
            collection.data.push(doc)
          })
        // }
        })
      } else {
        // console.log(`No chunks available for ${collection.name}`)
      }
    // }
    })
  }

  IncremenentalAdapter.prototype._initializeIDB = function(callback) {
    console.time('initializeIDB')
    const openRequest = indexedDB.open('IncrementalAdapterIDB', 1);

    openRequest.onupgradeneeded = e => {
      const db = e.target.result
      if (db.objectStoreNames.contains('Store')) {
        throw new Error('todo')
        // TODO: Finish this
      }

      const store = db.createObjectStore('Store', { keyPath: 'key' })
    }

    openRequest.onsuccess = e => {
      console.timeEnd('initializeIDB')
      this.idb = e.target.result
      callback()
    }

    openRequest.onerror = e => {
      throw e
    }
  }

  IncremenentalAdapter.prototype._saveChunks = function(chunks, callback) {
    if (!this.idb) {
      this._initializeIDB(() => {
        this._saveChunks(chunks, callback)
      })
      return
    }
    console.warn(`--- _saveChunks`)

    console.time('saveChunks')

    let tx = this.idb.transaction(['Store'], 'readwrite')
    tx.oncomplete = () => {
      console.timeEnd('saveChunks')
      console.timeEnd('exportDatabase')
      console.warn(`calling callback, all done!`)
      callback()
    }
    // TODO: Error handling

    let store = tx.objectStore('Store')

    console.time('put')
    chunks.forEach(object => {
      store.put(object)
    })
    console.timeEnd('put')
  }

  IncremenentalAdapter.prototype._getAllChunks = function(callback) {
    if (!this.idb) {
      this._initializeIDB(() => {
        this._getAllChunks(callback)
      })
      return
    }

    console.warn(`--- _getAllChunks`)
    console.time('getChunks')

    let tx = this.idb.transaction(['Store'], 'readonly')

    // TODO: Error handling

    const request = tx.objectStore('Store').getAll()
    request.onsuccess = e => {
      let chunks = e.target.result
      console.timeEnd('getChunks')
      callback(chunks)
    }
  }

  function start() {
    let adapter = new IncremenentalAdapter()
    db = new loki('indexed_tests', { adapter: adapter, verbose: true });

    let col = db.addCollection('test_collection')

    col.insert({  customId: 0,  val: 'hello', constraints: 100 });
    col.insert({  customId: 1,  val: 'hello1' });
    let h2 = col.insert({  customId: 2,  val: 'hello2' });
    let h3 = col.insert({  customId: 3,  val: 'hello3' });
    let h4 = col.insert({  customId: 4,  val: 'hello4' });
    let h5 = col.insert({  customId: 5,  val: 'hello5' });

    h2.val = 'UPDATED'
    col.update(h2)

    h3.val = 'UPDATED'
    col.update(h3)
    h3.val2 = 'added!'
    col.update(h3)

    col.remove(h4)

    let h6 = col.insert({  customId: 6,  val: 'hello6' });

    console.log(db)
    console.log(col)

    // console.log(JSON.parse(db.serialize()))

    console.log(col.lokiIdChanges)

    console.time('massAdd')
    const numberOfRecords = 65000
    for (let i = 0; i < numberOfRecords; i++) {
      col.insert({ mass: true, i, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' })
    }
    console.timeEnd('massAdd')

    // remove many contiguous records to have empty chunks
    const dataToDelete = col.data.slice(200, 95)
    col.remove(dataToDelete)

    // fuzz changes
    const numberOfDeletions = 5000
    for (let i = 0;i<numberOfDeletions;i++) {
      const id = Math.floor(Math.random() * col.data.length)
      col.remove(col.data[id])
    }

    const numberOfUpdates = 5000
    for (let i = 0;i<numberOfUpdates;i++) {
      const id = Math.floor(Math.random() * col.data.length)
      const doc = col.data[id]
      doc.blah = 'UPDATED_' + doc.blah
      col.update(doc)
    }

    db.saveDatabase((e) => {
      e && console.error(e)
      console.log('Database saved!')

      // test loading
      let db2 = new loki('indexed_tests', { adapter: new IncremenentalAdapter(), verbose: true });
      db2.loadDatabase({}, () => {
        console.log(`Loaded database!`)

        // make sure the two databases are identical
        db.collections.forEach((col, ci) => {
          if (!col.data.every((el, i) => {
            const val = JSON.stringify(db2.collections[ci].data[i]) === JSON.stringify(el)
            if (!val) {
              debugger
            }
            return val
          }
          )) {
            debugger
            throw new Error('different dbs')
          }
        })
        console.log(`Passed the checks!`)
      })
    })
  }

  // ------ IndexedDB performance tests -------




  function modifyEntireIDB(create = false) {
      console.time('saveIDB')
      create && indexedDB.deleteDatabase("IDBTest2")
    let openRequest = indexedDB.open('IDBTest2', 1);
    openRequest.onupgradeneeded = e => {
      if (create) {

        var thisDB = e.target.result;

        let objectStore = thisDB.createObjectStore('TestStore2', { keyPath: 'key' });
      } else {
        throw new Error('idb doesnt exist')
      }
    }
    openRequest.onsuccess = e => {
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')

      tx.oncomplete = () => {
      console.timeEnd('saveIDB')
      }

      let store = tx.objectStore('TestStore2')

      const method = create ? 'add' : 'put'

      store[method]({ key: 'metadata', val: { collections: {} } })


      console.time('addmany')
      for (let i = 0; i < 650; i++) {
        let bsObject = Array(100).fill(null).map(() => ({ foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }))

        store[method]({ key: 'bchunk.blah.' + i, val: JSON.stringify(bsObject) })
      }
      console.timeEnd('addmany')

    }
  }

  function createIDB() {
    modifyEntireIDB(true)
  }

  function modifyIDB() {
    console.time('modifyIDB')
    let openRequest = indexedDB.open('IDBTest2', 1);
    openRequest.onupgradeneeded = e => {
      throw new Error('idb doesnt exist')
    }
    openRequest.onsuccess = e => {
    console.time('sync-lock-time')
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')

      tx.oncomplete = () => {
      console.timeEnd('modifyIDB')
      }

      let store = tx.objectStore('TestStore2')

      let bsObject = Array(100).fill(null).map(() => ({ foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }))

      store.put({ key: 'bchunk.blah.0', val: JSON.stringify(bsObject) })
    console.timeEnd('sync-lock-time')

    }
  }

  function createIDBBigBlob() {
      console.time('saveIDBBlob')
      indexedDB.deleteDatabase("IDBTestBlob")
    let openRequest = indexedDB.open('IDBTestBlob', 1);
    openRequest.onupgradeneeded = e => {
      var thisDB = e.target.result;

      let objectStore = thisDB.createObjectStore('TestStore2', { keyPath: 'key' });
    }
    openRequest.onsuccess = e => {
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')
      let store = tx.objectStore('TestStore2')

      let loki = { chunks: [] }
      console.time('addmany')
      for (let i = 0; i < 65000; i++) {
        let bsObject = { foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }

        loki.chunks.push({ key: 'chunk.blah.' + i, val: bsObject })
      }
      console.timeEnd('addmany')


      store.add({ key: 'db', val: JSON.stringify(loki) })

      tx.oncomplete = () => {
      console.timeEnd('saveIDBBlob')
      }
    }
  }

  start()
  // createIDB() // takes 250-300ms in Safari to insert 650 chunks, 100 elements each; chrome: 350; firefox: 125
  // modifyIDB() // ~12-20ms for saving one 100-el chunk; chrome: 10ms; ff: 15
  // modifyEntireIDB() // worst case scenario: 210-240ms; ff: 100-150
  // createIDBBigBlob() // 360ms - 65000 elements in one big JSON chunk; chrome: 360-400; ff: 350-400
</script>
