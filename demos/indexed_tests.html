<!doctype html>
<head>
  <script type="text/javascript" src="../src/lokijs.js"></script>
</head>
<h2>Hi!</h2>

<script>
  var db



  function IncremenentalAdapter() {
    this.mode = 'reference'
    this.chunkSize = 100
    // this.chunkSize = 5
    this.idb = null // will be lazily loaded on first operation that needs it
  }

  // chunkId - index of the data chunk - e.g. chunk 0 will be lokiIds 0-99
  IncremenentalAdapter.prototype._getChunk = function(collection, chunkId) {
    // 0-99, 100-199, etc.
    // (loki starts $loki ids with 1, but that could change so just to be safe…)
    const minId = chunkId * this.chunkSize
    const maxId = minId + this.chunkSize - 1

    // use idIndex to find first collection.data position within the $loki range
    const idIndex = collection.idIndex
    let firstDataPosition = null
    for (let i = 0, length = idIndex.length; i < length; i++) {
      // TODO: doing this by binary search would be faster
      if (idIndex[i] >= minId && idIndex[i] <= maxId) {
        firstDataPosition = idIndex[i]
        break
      }
    }

    if (firstDataPosition === null) {
      // no elements in this chunk
      return []
    }

    // sanity check
    // TODO: remove me
    const firstElement = collection.data[firstDataPosition]
    if (!(firstElement && firstElement.$loki >= minId && firstElement.$loki <= maxId)) {
      throw new Error('broken invariant firstelement')
    }

    // this will have *up to* `this.chunkSize` elements (might have less, because $loki ids
    // will have holes when data is deleted)
    const chunkData = []
    for (let i = firstDataPosition; true; i++) {
      const element = collection.data[i]
      // TODO: Remove sanity check
      if (element && element.$loki < minId) {
        throw new Error('broken invariant minid')
      }
      if (element && element.$loki <= maxId) {
        chunkData.push(element)
      } else {
        break
      }
    }

    // TODO: Remove sanity check
    if (chunkData.length > this.chunkSize) {
      throw new Error('broken invariant - chunk size')
    }

    return chunkData
  }

  IncremenentalAdapter.prototype.exportDatabase = function(dbname, loki, callback) {
    console.warn(`-- exportDatabase - begin`)
    console.time('exportDatabase')
    console.log(loki.collections[0].lokiIdChanges)

    let chunksToSave = []

    console.time('makeChunks')
    loki.collections.forEach(collection => {
      // TODO: do we need to separate inserted and updated?
      // get deduplicated ids
      // const idsToSave = new Set(changes.inserted.concat(changes.updated))
      // const idsToRemove = new Set(changes.removed)
      // idsToRemove.forEach(id => {
        //   idsToSave.delete(id)
        // })
      // const changes = collection.lokiIdChanges
      // const dirtyLokiIds = new Set(changes.inserted.concat(changes.updated).concat(changes.removed))
      // collection.lokiIdChanges = null

      // // prepare chunks to save and remove
      // idsToSave.forEach(id => {
      //   // TODO: error handling on get
      //   chunksToSave.push([collection.name + '.' + id, collection.get(id)])
      // })
      // idsToRemove.forEach(id => {
      //   chunkIdsToRemove.push(collection.name + '.' + id)
      // })

      console.time('get dirty chunk ids')
      const dirtyChunks = new Set()
      const changes = collection.lokiIdChanges
      changes.inserted.concat(changes.updated).concat(changes.removed).forEach(lokiId => {
        const chunkId = lokiId / this.chunkSize | 0
        dirtyChunks.add(chunkId)
      })
      collection.lokiIdChanges = null
      console.timeEnd('get dirty chunk ids')

      console.time('get chunks&serialize')
      dirtyChunks.forEach(chunkId => {
        // console.time('get chunk')
        const chunkData = this._getChunk(collection, chunkId)
        // console.timeEnd('get chunk')
        // we must stringify, because IDB is asynchronous, and underlying objects are mutable
        // console.time('stringify chunk')
        const chunkJSON = JSON.stringify(chunkData)
        chunksToSave.push({ key: collection.name + '.chunk.' + chunkId, value: chunkJSON})
        // console.timeEnd('stringify chunk')
      })
      console.timeEnd('get chunks&serialize')

      // clear out data as we won't be saving it
      collection.data = []
    })
    console.timeEnd('makeChunks')

    console.time('loki-serialized')
    const serializedMetadata = JSON.stringify(loki)
    loki = null // allow GC of the DB copy

    console.log(chunksToSave)
    // console.log(chunkIdsToRemove)
    console.log(JSON.parse(serializedMetadata))

    chunksToSave.push({ key: 'loki', value: serializedMetadata })
    console.timeEnd('loki-serialized')

    // TODO: Clear out lokiChangedIds flags on original database

    this._saveChunks(chunksToSave, callback)




    // if (success) {
    //   callback(null);
    // }
    // else {
    //   callback(new Error("some error occurred."));
    // }
  }



  IncremenentalAdapter.prototype.loadDatabase = function(dbname, callback) {
    console.warn(`-- loadDatabase - begin`)
    console.time('loadDatabase')
    this._getAllChunks(chunks => {

      if (!chunks.length) {
        console.log(`No chunks`)
        callback(null)
        return
      }

      console.log(`Found chunks:`, chunks)

      // sort chunks in place to load data in the right order (ascending loki ids)
      // TODO: Maybe not necessary if IDB provides certain sort guarantees?
      console.time('sort')
      chunks.sort(function(a, b){
        if(a.key < b.key) return -1;
        if(a.key > b.key) return 1;
        return 0;
      });
      console.timeEnd('sort')
      console.log(`Sorted chunks`, chunks)

      // repack chunks into a map
      let loki
      let collections = {}

      console.time('repack')
      chunks.forEach(({ key, value }) => {
        if (key === 'loki') {
          loki = value
        } else if (key.includes('.')) {
          const keySegments = key.split('.')
          if (keySegments.length === 3 && keySegments[1] === 'chunk') {
            const colName = keySegments[0]
            if (collections[colName]) {
              collections[colName].push(value)
            } else {
              collections[colName] = [value]
            }
          } else {
            throw new Error('unknown chunk')
          }
        } else {
          throw new Error('unknown chunk')
        }
      })
      chunks = null
      console.timeEnd('repack')
      console.log(`Collections`, collections)

      // TODO: Validate collection chunks?
      if (!loki) {
        throw new Error('missing loki…')
      }

      // parse Loki object
      console.time('parse/populate')
      loki = JSON.parse(loki)
      console.log(`Parsed loki object`, loki)

      // populate collections with data
      loki.collections.forEach(collection => {
        const dataChunks = collections[collection.name]

        if (dataChunks) {
          console.log(`Importing ${dataChunks.length} chunks into ${collection.name}`)

          dataChunks.forEach((chunkObj, i) => {
            const chunk = JSON.parse(chunkObj)
            chunkObj = null
            dataChunks[i] = null

            chunk.forEach(doc => {
              collection.data.push(doc)
            })
          })
        } else {
          console.log(`No chunks available for ${collection.name}`)
        }
      })
      collections = null
      console.timeEnd('parse/populate')

      // instantiate actual Loki object
      console.timeEnd('loadDatabase')
      console.log(`Loaded Loki database!`, loki)
      callback(loki)
    })


    // if (success) {
    //   callback(newSerialized);
    // }
    // else {
    //   callback(new Error("some error"));
    // }
  }

  IncremenentalAdapter.prototype._initializeIDB = function(callback) {
    console.time('initializeIDB')
    const openRequest = indexedDB.open('IncrementalAdapterIDB', 1);

    openRequest.onupgradeneeded = e => {
      const db = e.target.result
      if (db.objectStoreNames.contains('Store')) {
        throw new Error('todo')
        // TODO: Finish this
      }

      const store = db.createObjectStore('Store', { keyPath: 'key' })
    }

    openRequest.onsuccess = e => {
      console.timeEnd('initializeIDB')
      this.idb = e.target.result
      callback()
    }

    openRequest.onerror = e => {
      throw e
    }
  }

  IncremenentalAdapter.prototype._saveChunks = function(chunks, callback) {
    if (!this.idb) {
      this._initializeIDB(() => {
        this._saveChunks(chunks, callback)
      })
      return
    }
    console.warn(`--- _saveChunks`)

    console.time('saveChunks')

    let tx = this.idb.transaction(['Store'], 'readwrite')
    tx.oncomplete = () => {
      console.timeEnd('saveChunks')
      console.timeEnd('exportDatabase')
      console.warn(`calling callback, all done!`)
      callback()
    }
    // TODO: Error handling

    let store = tx.objectStore('Store')

    console.time('put')
    chunks.forEach(object => {
      store.put(object)
    })
    console.timeEnd('put')
  }

  IncremenentalAdapter.prototype._getAllChunks = function(callback) {
    if (!this.idb) {
      this._initializeIDB(() => {
        this._getAllChunks(callback)
      })
      return
    }

    console.warn(`--- _getAllChunks`)
    console.time('getChunks')

    let tx = this.idb.transaction(['Store'], 'readonly')

    // TODO: Error handling

    const request = tx.objectStore('Store').getAll()
    request.onsuccess = e => {
      let chunks = e.target.result
      console.timeEnd('getChunks')
      callback(chunks)
    }
  }

  function start() {
    let adapter = new IncremenentalAdapter()
    db = new loki('indexed_tests', { adapter: adapter, verbose: true });

    let col = db.addCollection('test_collection')

    col.insert({  customId: 0,  val: 'hello', constraints: 100 });
    col.insert({  customId: 1,  val: 'hello1' });
    let h2 = col.insert({  customId: 2,  val: 'hello2' });
    let h3 = col.insert({  customId: 3,  val: 'hello3' });
    let h4 = col.insert({  customId: 4,  val: 'hello4' });
    let h5 = col.insert({  customId: 5,  val: 'hello5' });

    h2.val = 'UPDATED'
    col.update(h2)

    h3.val = 'UPDATED'
    col.update(h3)
    h3.val2 = 'added!'
    col.update(h3)

    col.remove(h4)

    let h6 = col.insert({  customId: 6,  val: 'hello6' });

    console.log(db)
    console.log(col)

    // console.log(JSON.parse(db.serialize()))

    console.log(col.lokiIdChanges)

    console.time('massAdd')
    for (let i = 0; i < 65000; i++) {
      col.insert({ mass: true, i, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' })
    }
    console.timeEnd('massAdd')



    db.saveDatabase((e) => {
      e && console.error(e)
      console.log('Database saved!')

      // test loading
      let db2 = new loki('indexed_tests', { adapter: new IncremenentalAdapter(), autoload: true, verbose: true });
    })
  }

  // ------ IndexedDB performance tests -------




  function modifyEntireIDB(create = false) {
      console.time('saveIDB')
      create && indexedDB.deleteDatabase("IDBTest2")
    let openRequest = indexedDB.open('IDBTest2', 1);
    openRequest.onupgradeneeded = e => {
      if (create) {

        var thisDB = e.target.result;

        let objectStore = thisDB.createObjectStore('TestStore2', { keyPath: 'key' });
      } else {
        throw new Error('idb doesnt exist')
      }
    }
    openRequest.onsuccess = e => {
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')

      tx.oncomplete = () => {
      console.timeEnd('saveIDB')
      }

      let store = tx.objectStore('TestStore2')

      const method = create ? 'add' : 'put'

      store[method]({ key: 'metadata', val: { collections: {} } })


      console.time('addmany')
      for (let i = 0; i < 650; i++) {
        let bsObject = Array(100).fill(null).map(() => ({ foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }))

        store[method]({ key: 'bchunk.blah.' + i, val: JSON.stringify(bsObject) })
      }
      console.timeEnd('addmany')

    }
  }

  function createIDB() {
    modifyEntireIDB(true)
  }

  function modifyIDB() {
    console.time('modifyIDB')
    let openRequest = indexedDB.open('IDBTest2', 1);
    openRequest.onupgradeneeded = e => {
      throw new Error('idb doesnt exist')
    }
    openRequest.onsuccess = e => {
    console.time('sync-lock-time')
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')

      tx.oncomplete = () => {
      console.timeEnd('modifyIDB')
      }

      let store = tx.objectStore('TestStore2')

      let bsObject = Array(100).fill(null).map(() => ({ foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }))

      store.put({ key: 'bchunk.blah.0', val: JSON.stringify(bsObject) })
    console.timeEnd('sync-lock-time')

    }
  }

  function createIDBBigBlob() {
      console.time('saveIDBBlob')
      indexedDB.deleteDatabase("IDBTestBlob")
    let openRequest = indexedDB.open('IDBTestBlob', 1);
    openRequest.onupgradeneeded = e => {
      var thisDB = e.target.result;

      let objectStore = thisDB.createObjectStore('TestStore2', { keyPath: 'key' });
    }
    openRequest.onsuccess = e => {
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')
      let store = tx.objectStore('TestStore2')

      let loki = { chunks: [] }
      console.time('addmany')
      for (let i = 0; i < 65000; i++) {
        let bsObject = { foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }

        loki.chunks.push({ key: 'chunk.blah.' + i, val: bsObject })
      }
      console.timeEnd('addmany')


      store.add({ key: 'db', val: JSON.stringify(loki) })

      tx.oncomplete = () => {
      console.timeEnd('saveIDBBlob')
      }
    }
  }

  start()
  // createIDB() // takes 250-300ms in Safari to insert 650 chunks, 100 elements each; chrome: 350; firefox: 125
  // modifyIDB() // ~12-20ms for saving one 100-el chunk; chrome: 10ms; ff: 15
  // modifyEntireIDB() // worst case scenario: 210-240ms; ff: 100-150
  // createIDBBigBlob() // 360ms - 65000 elements in one big JSON chunk; chrome: 360-400; ff: 350-400
</script>
