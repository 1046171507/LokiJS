<!doctype html>
<head>
  <script type="text/javascript" src="../src/lokijs.js"></script>
</head>
<h2>Hi!</h2>

<script>
  var db

  function IncremenentalAdapter() {
    this.mode = 'reference'
    // this.chunkSize = 100
    this.chunkSize = 5
  }

  // chunkId - index of the data chunk - e.g. chunk 0 will be lokiIds 0-99
  IncremenentalAdapter.prototype._getChunk = function(collection, chunkId) {
    // 0-99, 100-199, etc.
    // (loki starts $loki ids with 1, but that could change so just to be safeâ€¦)
    const minId = chunkId * this.chunkSize
    const maxId = minId + this.chunkSize - 1

    // use idIndex to find first collection.data position within the $loki range
    // const idIndex = collection.idIndex
    // let firstDataPosition = null
    // for (let i = 0; i < idIndex.length; i++) {
    //   // doing this by binary search would be faster but probably not necessary
    //   const lokiId = idIndex[i]
    //   if (lokiId >= minId && lokiId <= maxId) {
    //     firstDataPosition = idIndex
    //   }
    // }
    const firstDataPosition = collection.idIndex.findIndex(lokiId => lokiId >= minId && lokiId <= maxId)
    if (firstDataPosition === -1) {
      // no elements in this chunk
      return []
    }

    // sanity check
    // TODO: remove me
    const firstElement = collection.data[firstDataPosition]
    if (!(firstElement && firstElement.$loki >= minId && firstElement.$loki <= maxId)) {
      throw new Error('broken invariant firstelement')
    }

    // this will have *up to* `this.chunkSize` elements (might have less, because $loki ids
    // will have holes when data is deleted)
    const chunkData = []
    for (let i = firstDataPosition; true; i++) {
      const element = collection.data[i]
      // TODO: Remove sanity check
      if (element && element.$loki < minId) {
        throw new Error('broken invariant minid')
      }
      if (element && element.$loki <= maxId) {
        chunkData.push(element)
      } else {
        break
      }
    }

    // TODO: Remove sanity check
    if (chunkData.length > this.chunkSize) {
      throw new Error('broken invariant - chunk size')
    }

    return chunkData
  }

  IncremenentalAdapter.prototype.exportDatabase = function(dbname, loki, callback) {
    console.warn(`Begin export!`)
    console.log(loki.collections[0].lokiIdChanges)

    let chunksToSave = []

    loki.collections.forEach(collection => {
      // TODO: do we need to separate inserted and updated?
      // get deduplicated ids
      // const idsToSave = new Set(changes.inserted.concat(changes.updated))
      // const idsToRemove = new Set(changes.removed)
      // idsToRemove.forEach(id => {
        //   idsToSave.delete(id)
        // })
      // const changes = collection.lokiIdChanges
      // const dirtyLokiIds = new Set(changes.inserted.concat(changes.updated).concat(changes.removed))
      // collection.lokiIdChanges = null

      // // prepare chunks to save and remove
      // idsToSave.forEach(id => {
      //   // TODO: error handling on get
      //   chunksToSave.push([collection.name + '.' + id, collection.get(id)])
      // })
      // idsToRemove.forEach(id => {
      //   chunkIdsToRemove.push(collection.name + '.' + id)
      // })

      const dirtyChunks = new Set()

      const changes = collection.lokiIdChanges
      changes.inserted.concat(changes.updated).concat(changes.removed).forEach(lokiId => {
        const chunkId = lokiId / this.chunkSize | 0
        dirtyChunks.add(chunkId)
      })
      collection.lokiIdChanges = null

      dirtyChunks.forEach(chunkId => {
        const chunkData = this._getChunk(collection, chunkId)
        const chunkJSON = JSON.stringify(chunkData)
        chunksToSave.push([collection.name + '.chunk.' + chunkId, chunkJSON])
      })

      // clear out data as we won't be saving it
      collection.data = []
    })

    const serializedMetadata = JSON.stringify(loki)
    loki = null // allow GC of the DB copy

    console.log(chunksToSave)
    // console.log(chunkIdsToRemove)
    console.log(JSON.parse(serializedMetadata))


    // TODO: Clear out lokiChangedIds flags on original database



    // if (success) {
    //   callback(null);
    // }
    // else {
    //   callback(new Error("some error occurred."));
    // }
  }

  IncremenentalAdapter.prototype.loadDatabase = function(dbname, callback) {
    console.log(`Begin load!`)
    // if (success) {
    //   callback(newSerialized);
    // }
    // else {
    //   callback(new Error("some error"));
    // }
  }

  function start() {
    let adapter = new IncremenentalAdapter()
    db = new loki('indexed_tests', { adapter: adapter });

    let col = db.addCollection('test_collection')

    col.insert({  customId: 0,  val: 'hello', constraints: 100 });
    col.insert({  customId: 1,  val: 'hello1' });
    let h2 = col.insert({  customId: 2,  val: 'hello2' });
    let h3 = col.insert({  customId: 3,  val: 'hello3' });
    let h4 = col.insert({  customId: 4,  val: 'hello4' });
    let h5 = col.insert({  customId: 5,  val: 'hello5' });

    h2.val = 'UPDATED'
    col.update(h2)

    h3.val = 'UPDATED'
    col.update(h3)
    h3.val2 = 'added!'
    col.update(h3)

    col.remove(h4)

    let h6 = col.insert({  customId: 6,  val: 'hello6' });

    console.log(db)
    console.log(col)

    console.log(JSON.parse(db.serialize()))

    console.log(col.lokiIdChanges)



    db.saveDatabase((e) => {
      e && console.error(e)
      console.log('Database saved!')
    })
  }

  // ------ IndexedDB performance tests -------




  function modifyEntireIDB(create = false) {
      console.time('saveIDB')
      create && indexedDB.deleteDatabase("IDBTest2")
    let openRequest = indexedDB.open('IDBTest2', 1);
    openRequest.onupgradeneeded = e => {
      if (create) {

        var thisDB = e.target.result;

        let objectStore = thisDB.createObjectStore('TestStore2', { keyPath: 'key' });
      } else {
        throw new Error('idb doesnt exist')
      }
    }
    openRequest.onsuccess = e => {
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')

      tx.oncomplete = () => {
      console.timeEnd('saveIDB')
      }

      let store = tx.objectStore('TestStore2')

      const method = create ? 'add' : 'put'

      store[method]({ key: 'metadata', val: { collections: {} } })


      console.time('addmany')
      for (let i = 0; i < 650; i++) {
        let bsObject = Array(100).fill(null).map(() => ({ foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }))

        store[method]({ key: 'bchunk.blah.' + i, val: JSON.stringify(bsObject) })
      }
      console.timeEnd('addmany')

    }
  }

  function createIDB() {
    modifyEntireIDB(true)
  }

  function modifyIDB() {
    console.time('modifyIDB')
    let openRequest = indexedDB.open('IDBTest2', 1);
    openRequest.onupgradeneeded = e => {
      throw new Error('idb doesnt exist')
    }
    openRequest.onsuccess = e => {
    console.time('sync-lock-time')
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')

      tx.oncomplete = () => {
      console.timeEnd('modifyIDB')
      }

      let store = tx.objectStore('TestStore2')

      let bsObject = Array(100).fill(null).map(() => ({ foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }))

      store.put({ key: 'bchunk.blah.0', val: JSON.stringify(bsObject) })
    console.timeEnd('sync-lock-time')

    }
  }

  function createIDBBigBlob() {
      console.time('saveIDBBlob')
      indexedDB.deleteDatabase("IDBTestBlob")
    let openRequest = indexedDB.open('IDBTestBlob', 1);
    openRequest.onupgradeneeded = e => {
      var thisDB = e.target.result;

      let objectStore = thisDB.createObjectStore('TestStore2', { keyPath: 'key' });
    }
    openRequest.onsuccess = e => {
      let db = e.target.result

      let tx = db.transaction(['TestStore2'], 'readwrite')
      let store = tx.objectStore('TestStore2')

      let loki = { chunks: [] }
      console.time('addmany')
      for (let i = 0; i < 65000; i++) {
        let bsObject = { foo: 'asdasdasd', bar: 123, b: true, blah: 'accumsan congue. Lorem ipsum primis in nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam. nibh vel risus. Sed vel lectus. Ut sagittis, ipsum dolor quam' }

        loki.chunks.push({ key: 'chunk.blah.' + i, val: bsObject })
      }
      console.timeEnd('addmany')


      store.add({ key: 'db', val: JSON.stringify(loki) })

      tx.oncomplete = () => {
      console.timeEnd('saveIDBBlob')
      }
    }
  }

  start()
  // createIDB() // takes 250-300ms in Safari to insert 650 chunks, 100 elements each; chrome: 350; firefox: 125
  // modifyIDB() // ~12-20ms for saving one 100-el chunk; chrome: 10ms; ff: 15
  // modifyEntireIDB() // worst case scenario: 210-240ms; ff: 100-150
  // createIDBBigBlob() // 360ms - 65000 elements in one big JSON chunk; chrome: 360-400; ff: 350-400
</script>
